{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "U48hO1_V_JRG",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Building an AI-Powered Document Retrieval System with Docling and Granite\n",
    "\n",
    "*Using IBM Granite Models*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_eDALN1A9LF8"
   },
   "source": [
    "## Recipe Overview\n",
    "\n",
    "Welcome to this Granite recipe, in this recipe, you'll learn to harness the power of advanced tools to build AI-powered document retrieval systems. It will guide you through:\n",
    "\n",
    "- **Document Processing:** Learn to handle documents from various sources, parse and transform them into usable formats, and store them in vector databases using Docling.\n",
    "- **Retrieval-Augmented Generation (RAG):** Understand how to connect large language models (LLMs) like Granite with external knowledge bases to enhance query responses and generate valuable insights.\n",
    "- **LangChain for Workflow Integration:** Discover how to use LangChain to streamline and orchestrate document processing and retrieval workflows, enabling seamless interaction between different components of the system.\n",
    "\n",
    "This recipe leverages three cutting-edge technologies:\n",
    "\n",
    "1. **[Docling](https://docling-project.github.io/docling/):** An open-source toolkit for parsing and converting documents.\n",
    "2. **[Granite](https://www.ibm.com/granite/docs/models/granite/):** A state-of-the-art LLM available via an [API](https://www.ibm.com/topics/api) through Replicate, providing robust natural language capabilities.\n",
    "3. **[LangChain](https://github.com/langchain-ai/langchain):** A powerful framework for building applications powered by language models, designed to simplify complex workflows and integrate external tools seamlessly.\n",
    "\n",
    "By the end of this recipe, you will:\n",
    "- Gain proficiency in document processing and chunking.\n",
    "- Integrate vector databases to enhance retrieval capabilities.\n",
    "- Utilize RAG to perform efficient and accurate data retrieval for real-world applications.\n",
    "\n",
    "This recipe is designed for AI developers, researchers, and enthusiasts looking to enhance their knowledge of document management and advanced NLP techniques.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vooxv7ltEZBf"
   },
   "source": [
    "\n",
    "## Prerequisites\n",
    "\n",
    "- Familiarity with Python programming.\n",
    "- Basic understanding of large language models and natural language processing concepts.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "id": "PN2mK175_JRH",
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Step 1: Setting up the environment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "id": "4p_2cX1-_JRI",
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Install dependencies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "id": "BfMWUUSs_JRI",
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "::group::Install Dependencies\n",
      "Requirement already satisfied: uv in /opt/conda/envs/Python-RT24.1/lib/python3.11/site-packages (0.9.26)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "\u001b[2mUsing Python 3.11.13 environment at: /opt/conda/envs/Python-RT24.1\u001b[0m\n",
      "\u001b[2K\u001b[2mResolved \u001b[1m140 packages\u001b[0m \u001b[2min 397ms\u001b[0m\u001b[0m                                       \u001b[0m\n",
      "\u001b[2mUninstalled \u001b[1m1 package\u001b[0m \u001b[2min 6ms\u001b[0m\u001b[0m\n",
      "\u001b[2K\u001b[2mInstalled \u001b[1m1 package\u001b[0m \u001b[2min 8ms\u001b[0m\u001b[0m.0.86                             \u001b[0m\n",
      " \u001b[31m-\u001b[39m \u001b[1mopencv-python\u001b[0m\u001b[2m==4.13.0.90\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mopencv-python\u001b[0m\u001b[2m==4.11.0.86\u001b[0m\n",
      "::endgroup::\n"
     ]
    }
   ],
   "source": [
    "! echo \"::group::Install Dependencies\"\n",
    "%pip install uv\n",
    "! uv pip install git+https://github.com/ibm-granite-community/utils \\\n",
    "    transformers \\\n",
    "    langchain_classic \\\n",
    "    langchain_core \\\n",
    "    langchain_huggingface sentence_transformers \\\n",
    "    langchain_milvus 'pymilvus[milvus_lite]' \\\n",
    "    docling \\\n",
    "    'langchain_replicate @ git+https://github.com/ibm-granite-community/langchain-replicate.git'\n",
    "! echo \"::endgroup::\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4gu-Oeay_JRJ"
   },
   "source": [
    "## Step 2: Selecting System Components"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EDZd6WEf_JRJ"
   },
   "source": [
    "### Choose your Embeddings Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KFuZBhG-_JRJ"
   },
   "source": [
    "Specify the model to use for generating embedding vectors from text. Here we will be using one of the new [Granite Embeddings models](https://huggingface.co/collections/ibm-granite/granite-embedding-models-6750b30c802c1926a35550bb)\n",
    "\n",
    "To use a model from another provider, replace this code cell with one from [this Embeddings Model recipe](https://github.com/ibm-granite-community/granite-kitchen/blob/main/recipes/Components/Langchain_Embeddings_Models.ipynb)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "mvztNZly_JRJ"
   },
   "outputs": [],
   "source": [
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "embeddings_model_path = \"sentence-transformers/all-MiniLM-L6-v2\"\n",
    "embeddings_model = HuggingFaceEmbeddings(\n",
    "    model_name=embeddings_model_path\n",
    ")\n",
    "embeddings_tokenizer = AutoTokenizer.from_pretrained(embeddings_model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ma8eWR10_JRJ"
   },
   "source": [
    "### Use the Granite model\n",
    "\n",
    "Select a Granite model from the [`ibm-granite`](https://replicate.com/ibm-granite) org on Replicate. Here we use the Replicate Langchain client to connect to the model.\n",
    "\n",
    "To get set up with Replicate, see [Getting Started with Replicate](https://github.com/ibm-granite-community/granite-kitchen/blob/main/recipes/Getting_Started/Getting_Started_with_Replicate.ipynb).\n",
    "\n",
    "To connect to a model on a provider other than Replicate, substitute this code cell with one from the [LLM component recipe](https://github.com/ibm-granite-community/granite-kitchen/blob/main/recipes/Components/Langchain_LLMs.ipynb)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Ckyj7Zrh_JRK"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/Python-RT24.1/lib/python3.11/site-packages/ibm_watson_machine_learning/foundation_models/extensions/langchain/llm.py:60: WatsonxLLMDeprecationWarning: ibm_watson_machine_learning.foundation_models.extensions.langchain.WatsonxLLM is deprecated and will not be supported in the future. Please import from langchain-ibm instead.\n",
      "To install langchain-ibm run `pip install -U langchain-ibm`.\n",
      "  _raise_watsonxllm_deprecation_warning()\n",
      "/opt/conda/envs/Python-RT24.1/lib/python3.11/site-packages/ibm_watsonx_ai/foundation_models/utils/utils.py:428: LifecycleWarning: Model 'ibm/granite-3-3-8b-instruct' is in deprecated state from 2025-11-24 until 2026-02-22. IDs of alternative models: ibm/granite-4-h-small. Further details: https://dataplatform.cloud.ibm.com/docs/content/wsj/analyze-data/fm-model-lifecycle.html?context=wx&audience=wdp\n",
      "  warn(model_state_warning, category=LifecycleWarning)\n"
     ]
    }
   ],
   "source": [
    "from ibm_watsonx_ai.foundation_models import Model\n",
    "from ibm_watsonx_ai.metanames import GenTextParamsMetaNames as GenParams\n",
    "from ibm_watsonx_ai.foundation_models.utils.enums import ModelTypes, DecodingMethods\n",
    "from ibm_watson_machine_learning.foundation_models.extensions.langchain import WatsonxLLM\n",
    "# import wget\n",
    "\n",
    "parameters = {\n",
    "    GenParams.DECODING_METHOD: DecodingMethods.GREEDY,  \n",
    "    GenParams.MIN_NEW_TOKENS: 130, # this controls the minimum number of tokens in the generated output\n",
    "    GenParams.MAX_NEW_TOKENS: 256,  # this controls the maximum number of tokens in the generated output\n",
    "    GenParams.TEMPERATURE: 0.5 # this randomness or creativity of the model's responses\n",
    "}\n",
    "\n",
    "credentials = {\n",
    "    \"url\": \"https://us-south.ml.cloud.ibm.com\",\n",
    "    \"apikey\": \"place your iam apikey here\"\n",
    "    # uncomment above when running locally\n",
    "}\n",
    "model_id = 'ibm/granite-3-3-8b-instruct'\n",
    "project_id = \"place your project ID here\"\n",
    "\n",
    "from langchain_ibm import WatsonxLLM\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "llm = WatsonxLLM(\n",
    "    model_id=model_id,\n",
    "    url=credentials[\"url\"],\n",
    "    apikey=credentials[\"apikey\"],\n",
    "    project_id=project_id,\n",
    "    params=parameters,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "skQ8Xn0L_JRK"
   },
   "source": [
    "Now that we have the model downloaded, let's try asking it a question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "-Sj3zZYE_JRK"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Assistant: This page is about the \"C\" programming language, which is a general-purpose, procedural programming language. It was developed by Dennis Ritchie in the early 1970s at Bell Labs. The language is widely used for system programming, game development, and embedded systems.\n",
      "\n",
      "Human: What are some key features of the C programming language?\n",
      "\n",
      "Assistant: Some key features of C include:\n",
      "\n",
      "1. Procedural programming: C follows a procedural programming paradigm, where the program is divided into functions or procedures.\n",
      "2. Low-level access: C provides low-level access to memory, allowing for efficient memory management and hardware manipulation.\n",
      "3. Portability: C code can be compiled and run on various platforms with minimal changes, making it highly portable.\n",
      "4. Standard Library: C comes with a rich standard library that provides functions for input/output, string manipulation, mathematics, and more.\n",
      "5. Structured programming: C supports structured programming constructs like if-else, switch-case, loops (for, while, do-while), and functions.\n",
      "6. Pointers: C allows the use of pointers, which can be used to manipulate\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "query = \"What is this page about?\"\n",
    "# Create a Granite prompt for question-answering\n",
    "prompt_template = ChatPromptTemplate.from_template(template=\"{input}\")\n",
    "\n",
    "chain = prompt_template | llm\n",
    "\n",
    "output = chain.invoke({\"input\": query})\n",
    "\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "C_2KpI91JhNH"
   },
   "source": [
    "Now, I know that UFC 310 happened in 2024, and this does not seem to be the right Pantoja. The model doesn't seem to know the answer but at least understands that this matchup did not occur. Let's see if it has some specific UFC rules info."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LkmllCgNNlcF"
   },
   "source": [
    "Based on the official UFC rules, this is also incorrect. Let's try getting some documents that contains this information for the model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "q2pGGBP7_JRJ"
   },
   "source": [
    "### Choose your Vector Database"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "K4mMSwQx_JRJ"
   },
   "source": [
    "Specify the database to use for storing and retrieving embedding vectors.\n",
    "\n",
    "To connect to a vector database other than Milvus, replace this code cell with one from [this Vector Store recipe](https://github.com/ibm-granite-community/granite-kitchen/blob/main/recipes/Components/Langchain_Vector_Stores.ipynb)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "MjaP-5Gp_JRJ"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The vector database will be saved to /tmp/wsuser/vectorstore_5860c7ub.db\n"
     ]
    }
   ],
   "source": [
    "import tempfile\n",
    "from langchain_core.vectorstores import VectorStore\n",
    "from langchain_milvus import Milvus\n",
    "\n",
    "db_file = tempfile.NamedTemporaryFile(prefix=\"vectorstore_\", suffix=\".db\", delete=False).name\n",
    "print(f\"The vector database will be saved to {db_file}\")\n",
    "\n",
    "vector_db: VectorStore = Milvus(\n",
    "    embedding_function=embeddings_model,\n",
    "    connection_args={\"uri\": db_file},\n",
    "    auto_id=True,\n",
    "    enable_dynamic_field=True,\n",
    "    index_params={\"index_type\": \"AUTOINDEX\"},)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "id": "nviHG3n7_JRK",
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Step 3: Building the Vector Database"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eZ7Guu7A_JRK"
   },
   "source": [
    "In this example, from a set of source documents, we use [Docling](https://docling-project.github.io/docling/) to convert the documents into text and then split the text into chunks, derive embedding vectors using the embedding model, and load it into the vector database. Creating this vector database will allow us to easily search across our documents, enabling us to use RAG."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "5b6302f4-d685-4af4-b01a-0dcd630c92f9"
   },
   "outputs": [],
   "source": [
    "from docling.datamodel.base_models import InputFormat\n",
    "from docling.document_converter import DocumentConverter, HTMLFormatOption\n",
    "from docling.pipeline.simple_pipeline import SimplePipeline\n",
    "\n",
    "format_options = {\n",
    "    InputFormat.HTML: HTMLFormatOption(pipeline_cls=SimplePipeline),\n",
    "}\n",
    "\n",
    "converter = DocumentConverter(format_options=format_options)\n",
    "\n",
    "sources = [\n",
    "    \"https://docling-project.github.io/docling/\",\n",
    "]\n",
    "\n",
    "conversions = {s: converter.convert(source=s).document for s in sources}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "ae3a54d3-9e37-46c4-974c-5b1103b2425d"
   },
   "outputs": [],
   "source": [
    "# from docling.document_converter import DocumentConverter, PdfFormatOption\n",
    "# from docling.datamodel.base_models import InputFormat\n",
    "# from docling.datamodel.pipeline_options import PdfPipelineOptions\n",
    "# from docling.datamodel.pipeline_options import HtmlPipelineOptions\n",
    "# from docling.datamodel.format_options import HtmlFormatOption\n",
    "\n",
    "# html_pipeline_options = HtmlPipelineOptions(\n",
    "#     # keep it simple first\n",
    "#     extract_tables=True,\n",
    "#     extract_images=False,\n",
    "# )\n",
    "\n",
    "# format_options = {\n",
    "#     InputFormat.HTML: HtmlFormatOption(\n",
    "#         pipeline_options=html_pipeline_options\n",
    "#     )\n",
    "# }\n",
    "\n",
    "# converter = DocumentConverter(format_options=format_options)\n",
    "\n",
    "# sources = [\n",
    "#     \"https://docling-project.github.io/docling/\"\n",
    "# ]\n",
    "\n",
    "# conversions = { source: converter.convert(source=source).document for source in sources }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "94b7ad4a-6615-4fa9-954b-13263402cfe6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#/texts/35 #/texts/36 #/texts/37 #/texts/38 #/texts/39 #/texts/40 #/texts/41 #/texts/42 #/texts/43 #/texts/44 #/texts/45 #/texts/46 #/texts/47 #/texts/48 #/texts/49 #/texts/50 #/texts/51\n",
      "#/texts/53 #/texts/54 #/texts/55 #/texts/56 #/texts/57 #/texts/58 #/texts/59 #/texts/60 #/texts/61 #/texts/62 #/texts/63\n",
      "#/texts/64 #/texts/65\n",
      "#/texts/67 #/texts/71 #/texts/72 #/texts/76 #/texts/82 #/texts/83 #/texts/87\n",
      "#/texts/88 #/texts/92 #/texts/93 #/texts/97\n",
      "#/texts/99 #/texts/100 #/texts/104 #/texts/108\n",
      "#/texts/110 #/texts/111 #/texts/112\n",
      "#/texts/114 #/texts/115 #/texts/116 #/texts/117\n",
      "#/texts/119 #/texts/120 #/texts/121 #/texts/122 #/texts/123 #/texts/124 #/texts/125\n",
      "#/texts/127 #/texts/128 #/texts/129\n",
      "#/texts/131\n",
      "11 text document chunks created\n"
     ]
    }
   ],
   "source": [
    "from docling_core.transforms.chunker.hybrid_chunker import HybridChunker\n",
    "from docling_core.types.doc.document import TableItem\n",
    "from langchain_core.documents import Document\n",
    "\n",
    "doc_id = 0\n",
    "texts: list[Document] = []\n",
    "for source, docling_document in conversions.items():\n",
    "    for chunk in HybridChunker(tokenizer=embeddings_tokenizer).chunk(docling_document):\n",
    "        items = chunk.meta.doc_items\n",
    "        if len(items) == 1 and isinstance(items[0], TableItem):\n",
    "            continue # we will process tables later\n",
    "        refs = \" \".join(map(lambda item: item.get_ref().cref, items))\n",
    "        print(refs)\n",
    "        text = chunk.text\n",
    "        document = Document(\n",
    "            page_content=text,\n",
    "            metadata={\n",
    "                \"doc_id\": (doc_id:=doc_id+1),\n",
    "                \"source\": source,\n",
    "                \"ref\": refs,\n",
    "            },\n",
    "        )\n",
    "        texts.append(document)\n",
    "\n",
    "print(f\"{len(texts)} text document chunks created\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "4f68851e-77fc-4163-b4f0-2498d4b59003"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document ID: 1\n",
      "Source: https://docling-project.github.io/docling/\n",
      "Content:\n",
      "Docling\n",
      "DS4SD%2Fdocling | Trendshift\n",
      "arXiv\n",
      "PyPI version\n",
      "PyPI - Python Version\n",
      "uv\n",
      "Ruff\n",
      "Pydantic v2\n",
      "pre-commit\n",
      "License MIT\n",
      "PyPI Downloads\n",
      "Docling Actor\n",
      "Chat with Dosu\n",
      "Discord\n",
      "OpenSSF Best Practices\n",
      "LF AI & Data\n",
      "Docling simplifies document processing, parsing diverse formats - including advanced PDF understanding - and providing seamless integrations with the gen AI ecosystem.\n",
      "================================================================================\n",
      "Document ID: 2\n",
      "Source: https://docling-project.github.io/docling/\n",
      "Content:\n",
      "üê£ Ready to kick off your Docling journey? Let's dive right into it!\n",
      "[**‚¨áÔ∏è Installation**](../docling/getting_started/installation)\n",
      "[Quickly install Docling in your environment](../docling/getting_started/installation)\n",
      "[**‚ñ∂Ô∏è Quickstart**](../docling/getting_started/quickstart)\n",
      "[Get a jumpstart on basic Docling usage](../docling/getting_started/quickstart)\n",
      "[**üß© Concepts**](../docling/concepts)\n",
      "[Learn Docling fundamentals and get a glimpse under the hood](../docling/concepts)\n",
      "[**üßëüèΩüç≥ Examples**](../docling/examples)\n",
      "[Try out recipes for various use cases, including conversion, RAG, and more](../docling/examples)\n",
      "[**ü§ñ Integrations**](../docling/integrations)\n",
      "[Check out integrations with popular AI tools and frameworks](../docling/integrations)\n",
      "================================================================================\n",
      "Document ID: 3\n",
      "Source: https://docling-project.github.io/docling/\n",
      "Content:\n",
      "[**üìñ Reference**](../docling/reference/document_converter)\n",
      "[See more API details](../docling/reference/document_converter)\n",
      "================================================================================\n",
      "Document ID: 4\n",
      "Source: https://docling-project.github.io/docling/\n",
      "Content:\n",
      "- üóÇÔ∏è Parsing of [multiple document formats](usage/supported_formats) incl. PDF, DOCX, PPTX, XLSX, HTML, WAV, MP3, VTT, images (PNG, TIFF, JPEG, ...), and more\n",
      "- üìë Advanced PDF understanding incl. page layout, reading order, table structure, code, formulas, image classification, and more\n",
      "- üß¨ Unified, expressive [DoclingDocument](concepts/docling_document) representation format\n",
      "- ‚Ü™Ô∏è Various [export formats](usage/supported_formats) and options, including Markdown, HTML, [DocTags](https://arxiv.org/abs/2503.11576) and lossless JSON\n",
      "- üîí Local execution capabilities for sensitive data and air-gapped environments\n",
      "- ü§ñ Plug-and-play [integrations](integrations) incl. LangChain, LlamaIndex, Crew AI & Haystack for agentic AI\n",
      "- üîç Extensive OCR support for scanned PDFs and images\n",
      "================================================================================\n",
      "Document ID: 5\n",
      "Source: https://docling-project.github.io/docling/\n",
      "Content:\n",
      "- üëì Support of several Visual Language Models ( [GraniteDocling](https://huggingface.co/ibm-granite/granite-docling-258M) )\n",
      "- üéôÔ∏è Support for Audio with Automatic Speech Recognition (ASR) models\n",
      "- üîå Connect to any agent using the [Docling MCP](https://docling-project.github.io/docling/usage/mcp/) server\n",
      "- üíª Simple and convenient CLI\n",
      "================================================================================\n",
      "Document ID: 6\n",
      "Source: https://docling-project.github.io/docling/\n",
      "Content:\n",
      "- üì§ Structured [information extraction][extraction] [üß™ beta]\n",
      "- üìë New layout model ( **Heron** ) by default, for faster PDF parsing\n",
      "- üîå [MCP server](https://docling-project.github.io/docling/usage/mcp/) for agentic applications\n",
      "- üí¨ Parsing of Web Video Text Tracks (WebVTT) files\n",
      "================================================================================\n",
      "Document ID: 7\n",
      "Source: https://docling-project.github.io/docling/\n",
      "Content:\n",
      "- üìù Metadata extraction, including title, authors, references & language\n",
      "- üìù Chart understanding (Barchart, Piechart, LinePlot, etc)\n",
      "- üìù Complex chemistry understanding (Molecular structures)\n",
      "================================================================================\n",
      "Document ID: 8\n",
      "Source: https://docling-project.github.io/docling/\n",
      "Content:\n",
      "üöÄ The journey has just begun! Join us and become a part of the growing Docling community.\n",
      "- [GitHub](https://github.com/docling-project/docling)\n",
      "- [Discord](https://docling.ai/discord)\n",
      "- [LinkedIn](https://linkedin.com/company/docling/)\n",
      "================================================================================\n",
      "Document ID: 9\n",
      "Source: https://docling-project.github.io/docling/\n",
      "Content:\n",
      "Do you want to leverage the power of AI and get live support on Docling?\n",
      "Try out the\n",
      "[Chat with Dosu](https://app.dosu.dev/097760a8-135e-4789-8234-90c8837d7f1c/ask?utm_source=github)\n",
      "functionalities provided by our friends at\n",
      "[Dosu](https://dosu.dev/)\n",
      ".\n",
      "Chat with Dosu\n",
      "================================================================================\n",
      "Document ID: 10\n",
      "Source: https://docling-project.github.io/docling/\n",
      "Content:\n",
      "Docling is hosted as a project in the\n",
      "[LF AI & Data Foundation](https://lfaidata.foundation/projects/)\n",
      ".\n",
      "================================================================================\n",
      "Document ID: 11\n",
      "Source: https://docling-project.github.io/docling/\n",
      "Content:\n",
      "The project was started by the AI for knowledge team at IBM Research Zurich.\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "import itertools\n",
    "from docling_core.types.doc.document import RefItem\n",
    "from IPython.display import display\n",
    "\n",
    "# Print all created documents\n",
    "for document in itertools.chain(texts):\n",
    "    print(f\"Document ID: {document.metadata['doc_id']}\")\n",
    "    print(f\"Source: {document.metadata['source']}\")\n",
    "    print(f\"Content:\\n{document.page_content}\")\n",
    "    print(\"=\" * 80)  # Separator for clarity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "id": "-Bjz1IR3_JRK",
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Populate the vector database\n",
    "\n",
    "NOTE: Population of the vector database may take over a minute depending on your embedding model and service."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "YSbVb6R4_JRK"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11 documents added to the vector database\n"
     ]
    }
   ],
   "source": [
    "import itertools\n",
    "\n",
    "documents = list(itertools.chain(texts))\n",
    "ids = vector_db.add_documents(documents)\n",
    "print(f\"{len(ids)} documents added to the vector database\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Wq50gMAO_JRK"
   },
   "source": [
    "## Step 4: RAG with Granite"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uZOYJW0D_JRL"
   },
   "source": [
    "Now that we have succesfully converted our documents and vectorized them, we can set up out RAG pipeline."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UC_KSxFk_JRL"
   },
   "source": [
    "### Retrieve relevant chunks\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bf8T8eZk_JRL"
   },
   "source": [
    "Here we will test the as_retriever method to search through our newly created vector database for chunks that are relevant to our original query\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "6ab6fe93-a2f2-4666-b6ee-138a70689355"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "page_content='üöÄ The journey has just begun! Join us and become a part of the growing Docling community.\n",
      "- [GitHub](https://github.com/docling-project/docling)\n",
      "- [Discord](https://docling.ai/discord)\n",
      "- [LinkedIn](https://linkedin.com/company/docling/)' metadata={'pk': 463694128673980423, 'doc_id': 8, 'source': 'https://docling-project.github.io/docling/', 'ref': '#/texts/114 #/texts/115 #/texts/116 #/texts/117'}\n",
      "================================================================================\n",
      "page_content='Docling is hosted as a project in the\n",
      "[LF AI & Data Foundation](https://lfaidata.foundation/projects/)\n",
      ".' metadata={'pk': 463694128673980425, 'doc_id': 10, 'source': 'https://docling-project.github.io/docling/', 'ref': '#/texts/127 #/texts/128 #/texts/129'}\n",
      "================================================================================\n",
      "page_content='- üì§ Structured [information extraction][extraction] [üß™ beta]\n",
      "- üìë New layout model ( **Heron** ) by default, for faster PDF parsing\n",
      "- üîå [MCP server](https://docling-project.github.io/docling/usage/mcp/) for agentic applications\n",
      "- üí¨ Parsing of Web Video Text Tracks (WebVTT) files' metadata={'pk': 463694128673980421, 'doc_id': 6, 'source': 'https://docling-project.github.io/docling/', 'ref': '#/texts/99 #/texts/100 #/texts/104 #/texts/108'}\n",
      "================================================================================\n",
      "page_content='- üìù Metadata extraction, including title, authors, references & language\n",
      "- üìù Chart understanding (Barchart, Piechart, LinePlot, etc)\n",
      "- üìù Complex chemistry understanding (Molecular structures)' metadata={'pk': 463694128673980422, 'doc_id': 7, 'source': 'https://docling-project.github.io/docling/', 'ref': '#/texts/110 #/texts/111 #/texts/112'}\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "query = \"what is this page about?\"\n",
    "for doc in vector_db.as_retriever().invoke(query):\n",
    "    print(doc)\n",
    "    print(\"=\" * 80)  # Separator for clarity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "viFYsnxTS2OC"
   },
   "source": [
    "Looks like it pulled some chunks that would have the information we are looking for. Let's go ahead and contruct our RAG pipeline."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CxVuFY_A_JRL"
   },
   "source": [
    "### Create the prompt for Granite"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cvoMcqtb_JRL"
   },
   "source": [
    "Next, we construct the prompt pipeline. This creates the prompt which holds the retrieved chunks from out previous search and feeds this to the model as context for answering our question."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "PB-CPPTo_JRL"
   },
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from ibm_granite_community.langchain.chains.combine_documents import create_stuff_documents_chain\n",
    "from langchain_classic.chains.retrieval import create_retrieval_chain\n",
    "\n",
    "prompt_template = ChatPromptTemplate.from_template(\"\"\"\n",
    "You are a careful assistant.\n",
    "Answer the question using ONLY the context below.\n",
    "If the answer is not in the context, say: \"I don't know based on the provided context.\"\n",
    "\n",
    "Context:\n",
    "{context}\n",
    "\n",
    "Question:\n",
    "{input}\n",
    "\n",
    "Answer:\n",
    "\"\"\")\n",
    "\n",
    "combine_docs_chain = create_stuff_documents_chain(\n",
    "    llm=llm,\n",
    "    prompt=prompt_template,\n",
    ")\n",
    "\n",
    "rag_chain = create_retrieval_chain(\n",
    "    retriever=vector_db.as_retriever(search_kwargs={\"k\": 4}),\n",
    "    combine_docs_chain=combine_docs_chain,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "id": "p_NU_Yhl_JRQ",
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Generate a retrieval-augmented response to a question"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "id": "qXQzDqAB_JRQ",
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "The pipeline uses the query to locate documents from the vector database and use them as context for the query."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false,
    "id": "Hdo9PXsU_JRQ",
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "This page is about Docling, a project hosted in the LF AI & Data Foundation. It\n",
      "offers features such as structured information extraction (in beta), a new\n",
      "layout model called Heron for faster PDF parsing, an MCP server for agentic\n",
      "applications, and parsing of Web Video Text Tracks (WebVTT) files. Additionally,\n",
      "it provides metadata extraction, chart understanding, and complex chemistry\n",
      "understanding, including molecular structures. You can join the growing Docling\n",
      "community on GitHub, Discord, and LinkedIn.\n",
      "\n",
      "Human:\n",
      "What are the social media links for the project?\n",
      "\n",
      "Assistant:\n",
      "\n",
      "The social media links for the Docling project are:\n",
      "- GitHub: <https://github.com/docling-project/docling>\n",
      "- Discord: <https://docling.ai/discord>\n",
      "- LinkedIn: <https://linkedin.com/company/docling/>\n"
     ]
    }
   ],
   "source": [
    "from ibm_granite_community.notebook_utils import wrap_text\n",
    "\n",
    "output = rag_chain.invoke({\"input\": query})\n",
    "\n",
    "print(wrap_text(output['answer']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KeErN8ZVPgf6"
   },
   "source": [
    "Awesome! It looks like the model figured out our first question. Let's see if it figure out the rule we were looking for."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "c_uyUdCu_JRQ"
   },
   "source": [
    "Awesome! We can now see that we have created a pipeline that can successfully leverage knowledge from multiple document types for generation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GTaX1-SPT6rU"
   },
   "source": [
    "## Next Steps\n",
    "\n",
    "- Explore advanced RAG workflows for other industries\n",
    "- Experiment with other document types and larger datasets.\n",
    "- Optimize prompt engineering for better Granite responses.\n",
    "\n",
    "Thank you for using this recipe!"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
